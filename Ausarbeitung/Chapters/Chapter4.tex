% Chapter 4

\chapter{CA Guide Mobile Application} % Main chapter title

\label{frontend} % For referencing the chapter elsewhere, use \ref{Chapter1} 

\lhead{Chapter 4. \emph{CA Guide Frontend}} % This is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------

\section{Requirements}

The CA Guide mobile application has to display or play defined content when a specific context state is reached. Examples for entering defined geographical regions and other C. 

\section{Target Platform}

The target mobile plattform for the CA Guide frontend application is iOS 8.1. The targeted mobile device is an iPad mini with GPS sensor. This device was choosen for it's compact size and light weight, while still offering much more screen size than a normal smartphone, which is advantageous for displaying images and text in a size that is more comfortable to read.

\section{Architecture}

The application is separated in 5 different layers.

%TODO Figure without data
\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{layers-guide-app.png}
\caption{Layer Model of the Museum Guide Application}
\end{figure}

A fundamental requirement for the CA Guide front end, from a developer point of view, is the ability to record and replay recorded sensor readings of all accessed sensors and to automatically test the single layers using recorded sensor data and comparing it with it's expected result.

To achieve this goal, virtual sensors are introduced at three different levels of abstraction inside the sensor data processing foundation that provides the context information for the application.
 
\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{layers-guide-refined-app.png}
\caption{Layer model with virtual sensors}
\end{figure}

These three layers are important enough the deserve a name, so this foundation framework is called "Sensorbase" from now on. With a focus on clean and usable design it can evolve to a 

The following figure visualizes the different kind of data that is handled in every different layer, taking the accelerometer data processed by pedometer and statistics algorithms as an example. 

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{layers-app-dataflow-accelerometer.png}
\caption{Data flow between the lower layers of the Sensorbase framework}
\end{figure}

The pedometer algorithm in the low-level sensor data processing layer receives raw accelerometer data as input. It analyzes the data, detects single steps and passes them to the upper layer, the high-level sensor data processing. Here the single steps are aggregated to periods of slow and fast walking and walking statistics are updated.

The frequency of events passed to the next layer decreases from real-time data (100 updates per second), demanding very fast algorithms, to some seconds or minutes.

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{layers-app-dataflow-accelerometer.png}
\caption{Sequence Diagram for the Sensor Layers}
\end{figure}

Beside enabling automated unit tests at different abstraction levels, this layered virtual sensor concept has various other benefits:

\begin{itemize}
\item During development, a simulation of walking through a park or museum is possible, for manually testing not only algorithms of the lower layers, but also elements of the uppermost layer like different screen transitions or other UI behavior.
\item For demonstration the guide to customers or prospects a walk through a park can be simulated at the desk on a real device running the guide, beeing much more intuitive than showing only screen shots.
\item With an own class in the Sensor APIs layer acting as an adapter to the iOS APIs it is easier to migrate the algorithms to a different mobile platform, by rewriting this adapter class for the target platforms Sensor API and automatically translating the other sources that have no dependencies to the platform.
\end{itemize}



\begin{figure}[H]
\centering
\includegraphics[width=1.0\textwidth]{class-diagram-guide-app.png}
\caption{Simplified Class Diagram for Sensor Data Processing}
\end{figure}

Mock: useful for Testing the underlying layer,
Adapter for iOS Sensor API,
The Sensorbase class is a singleton and acts as facade for the whole framework. It provides a single interface to the set of interfaces of the sensorbase subsystem. Knowing which subsystem class is responsible for which call, it delegates client requests to the appropriate subsystem object (cf. \cite{gof}).

\subsection{Setup of Couchbase Server and Sync Gateway}

\section{Sensors Layers}

Sensor data is saved to couchbase database.
Later access for replay (development), testing and presentations.
The backend can access this saved data for later analysis.

Sensorbase debug view.
\cite{GCD-Reference}

\section{Application Logic}

If not walking fast load and play current content.

If display is on show actions that user has to opt in, if display is off play automatically. 

\section{Presentation Layer}

Mockups
XCode Storyboard
Final App Screenshots